{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Webscrapping con Beautiful Soup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El **web scraping** es el proceso de extracción de datos de sitios web de manera automatizada. Aprenderás los conceptos fundamentales y las herramientas necesarias para recolectar datos valiosos de la web, lo que te permitirá alimentar tus análisis y proyectos de Data Science con información fresca y relevante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Qué es?\n",
    "\n",
    "En términos sencillos, web scraping es como recolectar datos de una página web. Imagina que la web es una mina de información y que eres un minero recogiendo las gemas que necesitas para tu proyecto. En lugar de copiar y pegar manualmente, utilizamos código para automatizar el proceso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Por qué es importante el Web Scraping?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Acceso a datos no estructurados**: La mayoría de los datos en línea no están disponibles en formatos estructurados y listos para ser analizados. El web scraping te permite convertir datos no estructurados en un formato que puedas utilizar.\n",
    "\n",
    "* **Actualización de datos**: Muchas fuentes web se actualizan constantemente. El web scraping te permite mantener tus conjuntos de datos actualizados sin tener que hacerlo manualmente.\n",
    "\n",
    "* **Amplia gama de aplicaciones**: Desde la recopilación de datos de redes sociales hasta la obtención de precios de productos, el web scraping se utiliza en una amplia gama de aplicaciones de Data Science."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proceso de Web Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El web scraping generalmente sigue estos pasos:\n",
    "\n",
    "* **Hacer una solicitud HTTP**: obtenemos el contenido HTML de una página web.\n",
    "\n",
    "* **Análisis del HTML**: analizamos la estructura del HTML y encontrar los elementos que contienen los datos que necesitamos.\n",
    "\n",
    "* **Extracción de datos**: Una vez que hemos identificado los elementos, extraemos los datos relevantes.\n",
    "\n",
    "* **Almacenamiento de datos**: Podemos guardar los datos en un formato estructurado, como un archivo CSV o una base de datos.\n",
    "\n",
    "* **Limpieza y procesamiento**: A menudo, los datos extraídos necesitan ser limpiados y preprocesados antes de su análisis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es importante recordar que el web scraping puede tener implicaciones legales y éticas. Algunos sitios web prohíben la extracción de sus datos, y otros pueden limitar la velocidad a la que puedes hacer solicitudes para evitar la sobrecarga de sus servidores. Siempre debes respetar los términos de servicio de los sitios web y ser consciente de las leyes de privacidad y propiedad intelectual."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro HTML\n",
    "\n",
    "HTML (HyperText Markup Language) es el lenguaje de marcado utilizado para crear páginas web. Comprender los conceptos básicos de HTML es esencial para realizar web scraping, ya que te permite navegar y extraer datos de manera efectiva de sitios web.\n",
    "\n",
    "HTML utiliza etiquetas para estructurar el contenido de una página web. Aquí tienes una breve introducción a los conceptos básicos de HTML:\n",
    "\n",
    "1. **Etiquetas:** Las etiquetas son elementos fundamentales en HTML. Comienzan con `<` y terminan con `>`. Por ejemplo, `<p>` se utiliza para definir un párrafo, `<h1>` para encabezados de nivel 1, y `<a>` para enlaces.\n",
    "\n",
    "2. **Elementos:** Un elemento HTML se compone de una etiqueta de apertura, contenido y una etiqueta de cierre. Por ejemplo, `<p>Este es un párrafo.</p>`. El contenido es lo que se muestra en la página.\n",
    "\n",
    "3. **Atributos:** Las etiquetas pueden contener atributos que proporcionan información adicional sobre el elemento. Por ejemplo, en `<a href=\"https://www.ejemplo.com\">Enlace</a>`, \"href\" es un atributo que define la URL a la que el enlace apunta.\n",
    "\n",
    "4. **Anidamiento:** Los elementos HTML pueden anidarse dentro de otros elementos. Por ejemplo, un párrafo `<p>` puede contener un enlace `<a>`. Es importante entender la jerarquía de anidamiento para navegar eficazmente por la estructura de una página web.\n",
    "\n",
    "5. **Estructura:** Una página web típica tiene una estructura jerárquica con elementos como `<html>`, `<head>` (que contiene metadatos), `<body>` (que contiene el contenido visible), y muchos otros elementos como encabezados, listas, imágenes, etc.\n",
    "\n",
    "6. **Clases e IDs:** Los elementos HTML pueden tener clases y IDs, que son atributos utilizados para aplicar estilos y facilitar la identificación de elementos específicos en una página. Estos son útiles al realizar web scraping para seleccionar elementos específicos.\n",
    "\n",
    "Para realizar web scraping, necesitas comprender cómo se organiza y etiqueta la información en una página web para poder identificar y extraer los datos que necesitas. El conocimiento de HTML es una base fundamental para esta tarea, ya que te permite navegar y seleccionar elementos específicos en el código fuente de una página web.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beautiful Soup es una popular biblioteca de Python utilizada para analizar y extraer información de documentos HTML y XML de una manera sencilla y eficaz. Esta biblioteca proporciona herramientas para navegar y buscar elementos dentro de la estructura de un documento web, lo que la convierte en una herramienta esencial para tareas de web scraping y procesamiento de datos web. Beautiful Soup facilita la extracción de datos de una página web al proporcionar una interfaz amigable que permite acceder a etiquetas, atributos y contenido de manera intuitiva, lo que la convierte en una elección común entre los científicos de datos y desarrolladores que trabajan con datos web."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "import pandas as pd\n",
    "# from splinter import Browser\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option('max_colwidth', 800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, estamos listos para solicitar nuestra primera página web. No es nada complicado: guardamos la URL que queremos raspar en la variable URL, luego solicitamos la URL (requests.get (url)) y guardamos la respuesta en la variable de respuesta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.filmaffinity.com/es/topgen.php\"\n",
    "response = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pero necesitamos el contenido HTML de la página web solicitada, así que como siguiente paso guardamos el contenido de la respuesta a html:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = bs(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que hemos aprendido algo de HTML básico, finalmente podemos comenzar a extraer datos de soup. Simplemente escriba un nombre de etiqueta después de soup y un punto (como soup.title), y observe cómo se desarrolla la magia:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.h1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.h1.get_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Qué sucede si solo necesita el atributo de un elemento?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.a['href']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Sin utilizar método .find()\")\n",
    "print(soup.a)\n",
    "print(\"\")\n",
    "\n",
    "print(\"Utilizando método .find()\")\n",
    "print(soup.find(\"a\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find(\"a\").find('img')['src']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find_all('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_a = soup.find_all('a')\n",
    "\n",
    "for a in all_a[:5]:\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_a = soup.find_all('a')\n",
    "for a in all_a[:5]:\n",
    "    print(a.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_a = soup.find_all('a')\n",
    "for a in all_a[:5]:\n",
    "    print(a['href'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table align=\"left\">\n",
    " <tr><td width=\"80\"><img src=\"./img/ejercicio.png\" style=\"width:auto;height:auto\"></td>\n",
    "     <td style=\"text-align:left\">\n",
    "         <h3>Obtener textos menú cabecera</h3>\n",
    "Top FA| Rankings FA| Año 2023| Calendario Series| Últ. críticas| Tráilers| Premios\n",
    "      \n",
    "<ol>\n",
    "    <li>Obtén los textos con find_all y un bucle</li>\n",
    "    <li>Obtén los links con find_all y un bucle</li>\n",
    "    <li>Almacena la información en un dataframe</li>\n",
    "</ol>\n",
    "         \n",
    " </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find_all(\"a\")[4:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in soup.find_all(\"a\")[4:12]:\n",
    "    print(x.get_text())\n",
    "    print(x['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in soup.find_all(\"ul\")[0].find_all('a'):\n",
    "    print(x.get_text())\n",
    "    print(x['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "menu_dict = {\"Texto\": [],\n",
    "             \"Enlace\": []}\n",
    "\n",
    "for x in soup.find_all(\"a\")[4:12]:\n",
    "    menu_dict['Texto'].append(x.get_text())\n",
    "    menu_dict['Enlace'].append(x['href'])\n",
    "\n",
    "df = pd.DataFrame(menu_dict)\n",
    "df.to_csv(\"enlaces_menus.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table align=\"left\">\n",
    " <tr><td width=\"80\"><img src=\"./img/ejercicio.png\" style=\"width:auto;height:auto\"></td>\n",
    "     <td style=\"text-align:left\">\n",
    "         <h3>Obtener películas y nota</h3>\n",
    "      \n",
    "<ol>\n",
    "    <li>Obtén los títulos de las top 10 películas</li>\n",
    "    <li>Obtén el rating de las top 10 películas</li>\n",
    "    <li>Almacena la información en un dataframe</li>\n",
    "</ol>\n",
    "         \n",
    " </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#/html/body/div[3]/div/div/main/div[2]/ul/li[1]/ul/li[2]/div/div[2]/div[1]/a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find('div', class_=\"mc-title\").get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(soup.find_all('div', class_=\"mc-title\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in soup.find_all('div', class_=\"mc-title\")[:10]:\n",
    "    print(x.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in soup.find_all('div', class_=\"avg-rating\")[:10]:\n",
    "    print(x.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top10_dict = {\"Titulo\": [x.get_text() for x in soup.find_all('div', class_=\"mc-title\")[:10]],\n",
    "             \"Nota\": [x.get_text() for x in soup.find_all('div', class_=\"avg-rating\")[:10]]}\n",
    "df = pd.DataFrame(top10_dict)\n",
    "df.to_csv(\"top10.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
